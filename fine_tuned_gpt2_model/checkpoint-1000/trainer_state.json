{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.00945606358257153,
  "eval_steps": 500,
  "global_step": 1000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 9.45606358257153e-05,
      "grad_norm": 1.0188207626342773,
      "learning_rate": 0.00019995065603657316,
      "loss": 2.7581,
      "step": 10
    },
    {
      "epoch": 0.0001891212716514306,
      "grad_norm": 0.5808492302894592,
      "learning_rate": 0.00019980267284282717,
      "loss": 1.3162,
      "step": 20
    },
    {
      "epoch": 0.0002836819074771459,
      "grad_norm": 0.7999762296676636,
      "learning_rate": 0.00019955619646030802,
      "loss": 1.042,
      "step": 30
    },
    {
      "epoch": 0.0003782425433028612,
      "grad_norm": 1.091628909111023,
      "learning_rate": 0.0001992114701314478,
      "loss": 0.7292,
      "step": 40
    },
    {
      "epoch": 0.00047280317912857644,
      "grad_norm": 0.8328031301498413,
      "learning_rate": 0.00019876883405951377,
      "loss": 0.5557,
      "step": 50
    },
    {
      "epoch": 0.0005673638149542917,
      "grad_norm": 1.0808576345443726,
      "learning_rate": 0.0001982287250728689,
      "loss": 0.5437,
      "step": 60
    },
    {
      "epoch": 0.000661924450780007,
      "grad_norm": 1.0754785537719727,
      "learning_rate": 0.00019759167619387476,
      "loss": 0.438,
      "step": 70
    },
    {
      "epoch": 0.0007564850866057224,
      "grad_norm": 0.7668514847755432,
      "learning_rate": 0.0001968583161128631,
      "loss": 0.4032,
      "step": 80
    },
    {
      "epoch": 0.0008510457224314376,
      "grad_norm": 0.7394943237304688,
      "learning_rate": 0.0001960293685676943,
      "loss": 0.3913,
      "step": 90
    },
    {
      "epoch": 0.0009456063582571529,
      "grad_norm": 0.8488137722015381,
      "learning_rate": 0.00019510565162951537,
      "loss": 0.4026,
      "step": 100
    },
    {
      "epoch": 0.0010401669940828682,
      "grad_norm": 0.8459860682487488,
      "learning_rate": 0.00019408807689542257,
      "loss": 0.4229,
      "step": 110
    },
    {
      "epoch": 0.0011347276299085835,
      "grad_norm": 0.974929928779602,
      "learning_rate": 0.00019297764858882514,
      "loss": 0.3939,
      "step": 120
    },
    {
      "epoch": 0.0012292882657342988,
      "grad_norm": 0.7758134007453918,
      "learning_rate": 0.00019177546256839812,
      "loss": 0.374,
      "step": 130
    },
    {
      "epoch": 0.001323848901560014,
      "grad_norm": 0.9664754867553711,
      "learning_rate": 0.00019048270524660196,
      "loss": 0.331,
      "step": 140
    },
    {
      "epoch": 0.0014184095373857295,
      "grad_norm": 0.9845467805862427,
      "learning_rate": 0.0001891006524188368,
      "loss": 0.3349,
      "step": 150
    },
    {
      "epoch": 0.0015129701732114447,
      "grad_norm": 1.0105180740356445,
      "learning_rate": 0.00018763066800438636,
      "loss": 0.3382,
      "step": 160
    },
    {
      "epoch": 0.00160753080903716,
      "grad_norm": 0.7999916672706604,
      "learning_rate": 0.0001860742027003944,
      "loss": 0.3443,
      "step": 170
    },
    {
      "epoch": 0.0017020914448628752,
      "grad_norm": 0.9225190877914429,
      "learning_rate": 0.00018443279255020152,
      "loss": 0.3168,
      "step": 180
    },
    {
      "epoch": 0.0017966520806885905,
      "grad_norm": 0.8916237950325012,
      "learning_rate": 0.00018270805742745617,
      "loss": 0.3608,
      "step": 190
    },
    {
      "epoch": 0.0018912127165143058,
      "grad_norm": 1.3594692945480347,
      "learning_rate": 0.00018090169943749476,
      "loss": 0.3373,
      "step": 200
    },
    {
      "epoch": 0.001985773352340021,
      "grad_norm": 0.9952991604804993,
      "learning_rate": 0.00017901550123756906,
      "loss": 0.3397,
      "step": 210
    },
    {
      "epoch": 0.0020803339881657365,
      "grad_norm": 0.8566766381263733,
      "learning_rate": 0.00017705132427757895,
      "loss": 0.3535,
      "step": 220
    },
    {
      "epoch": 0.0021748946239914515,
      "grad_norm": 1.2729688882827759,
      "learning_rate": 0.00017501110696304596,
      "loss": 0.3294,
      "step": 230
    },
    {
      "epoch": 0.002269455259817167,
      "grad_norm": 0.9725219011306763,
      "learning_rate": 0.00017289686274214118,
      "loss": 0.2654,
      "step": 240
    },
    {
      "epoch": 0.0023640158956428825,
      "grad_norm": 0.9133902788162231,
      "learning_rate": 0.00017071067811865476,
      "loss": 0.3053,
      "step": 250
    },
    {
      "epoch": 0.0024585765314685975,
      "grad_norm": 0.622250497341156,
      "learning_rate": 0.00016845471059286887,
      "loss": 0.2789,
      "step": 260
    },
    {
      "epoch": 0.002553137167294313,
      "grad_norm": 1.034562587738037,
      "learning_rate": 0.00016613118653236518,
      "loss": 0.2861,
      "step": 270
    },
    {
      "epoch": 0.002647697803120028,
      "grad_norm": 0.5697981119155884,
      "learning_rate": 0.000163742398974869,
      "loss": 0.2552,
      "step": 280
    },
    {
      "epoch": 0.0027422584389457435,
      "grad_norm": 0.8980145454406738,
      "learning_rate": 0.00016129070536529766,
      "loss": 0.2826,
      "step": 290
    },
    {
      "epoch": 0.002836819074771459,
      "grad_norm": 0.864953339099884,
      "learning_rate": 0.00015877852522924732,
      "loss": 0.2795,
      "step": 300
    },
    {
      "epoch": 0.002931379710597174,
      "grad_norm": 0.8755021095275879,
      "learning_rate": 0.00015620833778521307,
      "loss": 0.3035,
      "step": 310
    },
    {
      "epoch": 0.0030259403464228895,
      "grad_norm": 0.6392521262168884,
      "learning_rate": 0.00015358267949789966,
      "loss": 0.2943,
      "step": 320
    },
    {
      "epoch": 0.0031205009822486045,
      "grad_norm": 0.7333807349205017,
      "learning_rate": 0.00015090414157503714,
      "loss": 0.2729,
      "step": 330
    },
    {
      "epoch": 0.00321506161807432,
      "grad_norm": 0.7244869470596313,
      "learning_rate": 0.00014817536741017152,
      "loss": 0.2986,
      "step": 340
    },
    {
      "epoch": 0.003309622253900035,
      "grad_norm": 0.6292321681976318,
      "learning_rate": 0.00014539904997395468,
      "loss": 0.2989,
      "step": 350
    },
    {
      "epoch": 0.0034041828897257505,
      "grad_norm": 0.7638192772865295,
      "learning_rate": 0.00014257792915650728,
      "loss": 0.2668,
      "step": 360
    },
    {
      "epoch": 0.003498743525551466,
      "grad_norm": 0.6577920317649841,
      "learning_rate": 0.00013971478906347806,
      "loss": 0.2569,
      "step": 370
    },
    {
      "epoch": 0.003593304161377181,
      "grad_norm": 0.5583338737487793,
      "learning_rate": 0.00013681245526846783,
      "loss": 0.2571,
      "step": 380
    },
    {
      "epoch": 0.0036878647972028965,
      "grad_norm": 0.627045750617981,
      "learning_rate": 0.00013387379202452917,
      "loss": 0.2491,
      "step": 390
    },
    {
      "epoch": 0.0037824254330286115,
      "grad_norm": 0.8836803436279297,
      "learning_rate": 0.00013090169943749476,
      "loss": 0.2679,
      "step": 400
    },
    {
      "epoch": 0.003876986068854327,
      "grad_norm": 1.090550184249878,
      "learning_rate": 0.00012789911060392294,
      "loss": 0.2871,
      "step": 410
    },
    {
      "epoch": 0.003971546704680042,
      "grad_norm": 0.9364948868751526,
      "learning_rate": 0.0001248689887164855,
      "loss": 0.2797,
      "step": 420
    },
    {
      "epoch": 0.0040661073405057575,
      "grad_norm": 0.8688815236091614,
      "learning_rate": 0.00012181432413965428,
      "loss": 0.2553,
      "step": 430
    },
    {
      "epoch": 0.004160667976331473,
      "grad_norm": 0.8005673289299011,
      "learning_rate": 0.00011873813145857249,
      "loss": 0.2685,
      "step": 440
    },
    {
      "epoch": 0.0042552286121571884,
      "grad_norm": 0.6640504598617554,
      "learning_rate": 0.0001156434465040231,
      "loss": 0.2612,
      "step": 450
    },
    {
      "epoch": 0.004349789247982903,
      "grad_norm": 0.7306011319160461,
      "learning_rate": 0.00011253332335643043,
      "loss": 0.2704,
      "step": 460
    },
    {
      "epoch": 0.0044443498838086185,
      "grad_norm": 0.7204407453536987,
      "learning_rate": 0.00010941083133185146,
      "loss": 0.2544,
      "step": 470
    },
    {
      "epoch": 0.004538910519634334,
      "grad_norm": 0.6536638736724854,
      "learning_rate": 0.00010627905195293135,
      "loss": 0.252,
      "step": 480
    },
    {
      "epoch": 0.0046334711554600495,
      "grad_norm": 0.9100165367126465,
      "learning_rate": 0.00010314107590781284,
      "loss": 0.2684,
      "step": 490
    },
    {
      "epoch": 0.004728031791285765,
      "grad_norm": 0.7633541226387024,
      "learning_rate": 0.0001,
      "loss": 0.2764,
      "step": 500
    },
    {
      "epoch": 0.0048225924271114795,
      "grad_norm": 0.6742371916770935,
      "learning_rate": 9.685892409218717e-05,
      "loss": 0.2821,
      "step": 510
    },
    {
      "epoch": 0.004917153062937195,
      "grad_norm": 0.7763785719871521,
      "learning_rate": 9.372094804706867e-05,
      "loss": 0.2632,
      "step": 520
    },
    {
      "epoch": 0.0050117136987629105,
      "grad_norm": 0.8958491086959839,
      "learning_rate": 9.058916866814858e-05,
      "loss": 0.248,
      "step": 530
    },
    {
      "epoch": 0.005106274334588626,
      "grad_norm": 0.6873896718025208,
      "learning_rate": 8.746667664356956e-05,
      "loss": 0.2432,
      "step": 540
    },
    {
      "epoch": 0.005200834970414341,
      "grad_norm": 0.6573609709739685,
      "learning_rate": 8.435655349597689e-05,
      "loss": 0.2307,
      "step": 550
    },
    {
      "epoch": 0.005295395606240056,
      "grad_norm": 0.8994394540786743,
      "learning_rate": 8.126186854142752e-05,
      "loss": 0.2326,
      "step": 560
    },
    {
      "epoch": 0.0053899562420657715,
      "grad_norm": 0.9342988729476929,
      "learning_rate": 7.818567586034577e-05,
      "loss": 0.2503,
      "step": 570
    },
    {
      "epoch": 0.005484516877891487,
      "grad_norm": 0.7322098612785339,
      "learning_rate": 7.513101128351454e-05,
      "loss": 0.2333,
      "step": 580
    },
    {
      "epoch": 0.0055790775137172025,
      "grad_norm": 0.7039010524749756,
      "learning_rate": 7.210088939607708e-05,
      "loss": 0.234,
      "step": 590
    },
    {
      "epoch": 0.005673638149542918,
      "grad_norm": 1.0645159482955933,
      "learning_rate": 6.909830056250527e-05,
      "loss": 0.2782,
      "step": 600
    },
    {
      "epoch": 0.0057681987853686325,
      "grad_norm": 0.6736692190170288,
      "learning_rate": 6.612620797547087e-05,
      "loss": 0.2348,
      "step": 610
    },
    {
      "epoch": 0.005862759421194348,
      "grad_norm": 0.8552494645118713,
      "learning_rate": 6.318754473153221e-05,
      "loss": 0.2676,
      "step": 620
    },
    {
      "epoch": 0.0059573200570200635,
      "grad_norm": 1.1753489971160889,
      "learning_rate": 6.0285210936521955e-05,
      "loss": 0.2818,
      "step": 630
    },
    {
      "epoch": 0.006051880692845779,
      "grad_norm": 0.8012839555740356,
      "learning_rate": 5.7422070843492734e-05,
      "loss": 0.2515,
      "step": 640
    },
    {
      "epoch": 0.006146441328671494,
      "grad_norm": 0.6890594363212585,
      "learning_rate": 5.4600950026045326e-05,
      "loss": 0.2173,
      "step": 650
    },
    {
      "epoch": 0.006241001964497209,
      "grad_norm": 0.9541995525360107,
      "learning_rate": 5.182463258982846e-05,
      "loss": 0.2454,
      "step": 660
    },
    {
      "epoch": 0.0063355626003229245,
      "grad_norm": 1.174910545349121,
      "learning_rate": 4.909585842496287e-05,
      "loss": 0.2427,
      "step": 670
    },
    {
      "epoch": 0.00643012323614864,
      "grad_norm": 0.8406751751899719,
      "learning_rate": 4.6417320502100316e-05,
      "loss": 0.2399,
      "step": 680
    },
    {
      "epoch": 0.0065246838719743554,
      "grad_norm": 0.9831319451332092,
      "learning_rate": 4.379166221478697e-05,
      "loss": 0.2613,
      "step": 690
    },
    {
      "epoch": 0.00661924450780007,
      "grad_norm": 0.560911238193512,
      "learning_rate": 4.12214747707527e-05,
      "loss": 0.2174,
      "step": 700
    },
    {
      "epoch": 0.0067138051436257855,
      "grad_norm": 0.6512361168861389,
      "learning_rate": 3.8709294634702376e-05,
      "loss": 0.2174,
      "step": 710
    },
    {
      "epoch": 0.006808365779451501,
      "grad_norm": 0.9352555871009827,
      "learning_rate": 3.6257601025131026e-05,
      "loss": 0.2378,
      "step": 720
    },
    {
      "epoch": 0.0069029264152772165,
      "grad_norm": 0.7181587219238281,
      "learning_rate": 3.386881346763483e-05,
      "loss": 0.2572,
      "step": 730
    },
    {
      "epoch": 0.006997487051102932,
      "grad_norm": 0.9688925743103027,
      "learning_rate": 3.154528940713113e-05,
      "loss": 0.2504,
      "step": 740
    },
    {
      "epoch": 0.0070920476869286465,
      "grad_norm": 0.7918856143951416,
      "learning_rate": 2.9289321881345254e-05,
      "loss": 0.2505,
      "step": 750
    },
    {
      "epoch": 0.007186608322754362,
      "grad_norm": 1.065440058708191,
      "learning_rate": 2.7103137257858868e-05,
      "loss": 0.2293,
      "step": 760
    },
    {
      "epoch": 0.0072811689585800775,
      "grad_norm": 0.7262635231018066,
      "learning_rate": 2.4988893036954053e-05,
      "loss": 0.238,
      "step": 770
    },
    {
      "epoch": 0.007375729594405793,
      "grad_norm": 0.7493136525154114,
      "learning_rate": 2.2948675722421086e-05,
      "loss": 0.2663,
      "step": 780
    },
    {
      "epoch": 0.007470290230231508,
      "grad_norm": 0.687692403793335,
      "learning_rate": 2.098449876243096e-05,
      "loss": 0.229,
      "step": 790
    },
    {
      "epoch": 0.007564850866057223,
      "grad_norm": 0.8894377946853638,
      "learning_rate": 1.9098300562505266e-05,
      "loss": 0.2405,
      "step": 800
    },
    {
      "epoch": 0.0076594115018829385,
      "grad_norm": 0.7751060724258423,
      "learning_rate": 1.7291942572543807e-05,
      "loss": 0.2284,
      "step": 810
    },
    {
      "epoch": 0.007753972137708654,
      "grad_norm": 0.8784632682800293,
      "learning_rate": 1.5567207449798515e-05,
      "loss": 0.2408,
      "step": 820
    },
    {
      "epoch": 0.007848532773534369,
      "grad_norm": 1.2214094400405884,
      "learning_rate": 1.3925797299605647e-05,
      "loss": 0.2697,
      "step": 830
    },
    {
      "epoch": 0.007943093409360084,
      "grad_norm": 0.6294669508934021,
      "learning_rate": 1.2369331995613653e-05,
      "loss": 0.2448,
      "step": 840
    },
    {
      "epoch": 0.0080376540451858,
      "grad_norm": 0.7864939570426941,
      "learning_rate": 1.0899347581163221e-05,
      "loss": 0.2093,
      "step": 850
    },
    {
      "epoch": 0.008132214681011515,
      "grad_norm": 0.8212189674377441,
      "learning_rate": 9.517294753398064e-06,
      "loss": 0.2133,
      "step": 860
    },
    {
      "epoch": 0.00822677531683723,
      "grad_norm": 0.9496117830276489,
      "learning_rate": 8.224537431601886e-06,
      "loss": 0.2552,
      "step": 870
    },
    {
      "epoch": 0.008321335952662946,
      "grad_norm": 0.7019485235214233,
      "learning_rate": 7.022351411174866e-06,
      "loss": 0.2548,
      "step": 880
    },
    {
      "epoch": 0.008415896588488661,
      "grad_norm": 0.7876652479171753,
      "learning_rate": 5.911923104577455e-06,
      "loss": 0.2224,
      "step": 890
    },
    {
      "epoch": 0.008510457224314377,
      "grad_norm": 0.7182528376579285,
      "learning_rate": 4.8943483704846475e-06,
      "loss": 0.2246,
      "step": 900
    },
    {
      "epoch": 0.008605017860140092,
      "grad_norm": 1.0720622539520264,
      "learning_rate": 3.970631432305694e-06,
      "loss": 0.2523,
      "step": 910
    },
    {
      "epoch": 0.008699578495965806,
      "grad_norm": 0.7630050182342529,
      "learning_rate": 3.1416838871368924e-06,
      "loss": 0.1988,
      "step": 920
    },
    {
      "epoch": 0.008794139131791522,
      "grad_norm": 0.7809790372848511,
      "learning_rate": 2.4083238061252567e-06,
      "loss": 0.2264,
      "step": 930
    },
    {
      "epoch": 0.008888699767617237,
      "grad_norm": 0.9540486931800842,
      "learning_rate": 1.771274927131139e-06,
      "loss": 0.2192,
      "step": 940
    },
    {
      "epoch": 0.008983260403442953,
      "grad_norm": 0.7909718155860901,
      "learning_rate": 1.231165940486234e-06,
      "loss": 0.2518,
      "step": 950
    },
    {
      "epoch": 0.009077821039268668,
      "grad_norm": 0.6808546781539917,
      "learning_rate": 7.885298685522235e-07,
      "loss": 0.2367,
      "step": 960
    },
    {
      "epoch": 0.009172381675094383,
      "grad_norm": 0.7399474382400513,
      "learning_rate": 4.438035396920004e-07,
      "loss": 0.2176,
      "step": 970
    },
    {
      "epoch": 0.009266942310920099,
      "grad_norm": 0.9644178748130798,
      "learning_rate": 1.973271571728441e-07,
      "loss": 0.2144,
      "step": 980
    },
    {
      "epoch": 0.009361502946745814,
      "grad_norm": 0.8355975151062012,
      "learning_rate": 4.934396342684e-08,
      "loss": 0.2273,
      "step": 990
    },
    {
      "epoch": 0.00945606358257153,
      "grad_norm": 1.6676242351531982,
      "learning_rate": 0.0,
      "loss": 0.2462,
      "step": 1000
    }
  ],
  "logging_steps": 10,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 7448907743232000.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
