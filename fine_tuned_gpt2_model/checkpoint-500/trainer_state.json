{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.004728031791285765,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 9.45606358257153e-05,
      "grad_norm": 1.0188207626342773,
      "learning_rate": 0.00019995065603657316,
      "loss": 2.7581,
      "step": 10
    },
    {
      "epoch": 0.0001891212716514306,
      "grad_norm": 0.5808492302894592,
      "learning_rate": 0.00019980267284282717,
      "loss": 1.3162,
      "step": 20
    },
    {
      "epoch": 0.0002836819074771459,
      "grad_norm": 0.7999762296676636,
      "learning_rate": 0.00019955619646030802,
      "loss": 1.042,
      "step": 30
    },
    {
      "epoch": 0.0003782425433028612,
      "grad_norm": 1.091628909111023,
      "learning_rate": 0.0001992114701314478,
      "loss": 0.7292,
      "step": 40
    },
    {
      "epoch": 0.00047280317912857644,
      "grad_norm": 0.8328031301498413,
      "learning_rate": 0.00019876883405951377,
      "loss": 0.5557,
      "step": 50
    },
    {
      "epoch": 0.0005673638149542917,
      "grad_norm": 1.0808576345443726,
      "learning_rate": 0.0001982287250728689,
      "loss": 0.5437,
      "step": 60
    },
    {
      "epoch": 0.000661924450780007,
      "grad_norm": 1.0754785537719727,
      "learning_rate": 0.00019759167619387476,
      "loss": 0.438,
      "step": 70
    },
    {
      "epoch": 0.0007564850866057224,
      "grad_norm": 0.7668514847755432,
      "learning_rate": 0.0001968583161128631,
      "loss": 0.4032,
      "step": 80
    },
    {
      "epoch": 0.0008510457224314376,
      "grad_norm": 0.7394943237304688,
      "learning_rate": 0.0001960293685676943,
      "loss": 0.3913,
      "step": 90
    },
    {
      "epoch": 0.0009456063582571529,
      "grad_norm": 0.8488137722015381,
      "learning_rate": 0.00019510565162951537,
      "loss": 0.4026,
      "step": 100
    },
    {
      "epoch": 0.0010401669940828682,
      "grad_norm": 0.8459860682487488,
      "learning_rate": 0.00019408807689542257,
      "loss": 0.4229,
      "step": 110
    },
    {
      "epoch": 0.0011347276299085835,
      "grad_norm": 0.974929928779602,
      "learning_rate": 0.00019297764858882514,
      "loss": 0.3939,
      "step": 120
    },
    {
      "epoch": 0.0012292882657342988,
      "grad_norm": 0.7758134007453918,
      "learning_rate": 0.00019177546256839812,
      "loss": 0.374,
      "step": 130
    },
    {
      "epoch": 0.001323848901560014,
      "grad_norm": 0.9664754867553711,
      "learning_rate": 0.00019048270524660196,
      "loss": 0.331,
      "step": 140
    },
    {
      "epoch": 0.0014184095373857295,
      "grad_norm": 0.9845467805862427,
      "learning_rate": 0.0001891006524188368,
      "loss": 0.3349,
      "step": 150
    },
    {
      "epoch": 0.0015129701732114447,
      "grad_norm": 1.0105180740356445,
      "learning_rate": 0.00018763066800438636,
      "loss": 0.3382,
      "step": 160
    },
    {
      "epoch": 0.00160753080903716,
      "grad_norm": 0.7999916672706604,
      "learning_rate": 0.0001860742027003944,
      "loss": 0.3443,
      "step": 170
    },
    {
      "epoch": 0.0017020914448628752,
      "grad_norm": 0.9225190877914429,
      "learning_rate": 0.00018443279255020152,
      "loss": 0.3168,
      "step": 180
    },
    {
      "epoch": 0.0017966520806885905,
      "grad_norm": 0.8916237950325012,
      "learning_rate": 0.00018270805742745617,
      "loss": 0.3608,
      "step": 190
    },
    {
      "epoch": 0.0018912127165143058,
      "grad_norm": 1.3594692945480347,
      "learning_rate": 0.00018090169943749476,
      "loss": 0.3373,
      "step": 200
    },
    {
      "epoch": 0.001985773352340021,
      "grad_norm": 0.9952991604804993,
      "learning_rate": 0.00017901550123756906,
      "loss": 0.3397,
      "step": 210
    },
    {
      "epoch": 0.0020803339881657365,
      "grad_norm": 0.8566766381263733,
      "learning_rate": 0.00017705132427757895,
      "loss": 0.3535,
      "step": 220
    },
    {
      "epoch": 0.0021748946239914515,
      "grad_norm": 1.2729688882827759,
      "learning_rate": 0.00017501110696304596,
      "loss": 0.3294,
      "step": 230
    },
    {
      "epoch": 0.002269455259817167,
      "grad_norm": 0.9725219011306763,
      "learning_rate": 0.00017289686274214118,
      "loss": 0.2654,
      "step": 240
    },
    {
      "epoch": 0.0023640158956428825,
      "grad_norm": 0.9133902788162231,
      "learning_rate": 0.00017071067811865476,
      "loss": 0.3053,
      "step": 250
    },
    {
      "epoch": 0.0024585765314685975,
      "grad_norm": 0.622250497341156,
      "learning_rate": 0.00016845471059286887,
      "loss": 0.2789,
      "step": 260
    },
    {
      "epoch": 0.002553137167294313,
      "grad_norm": 1.034562587738037,
      "learning_rate": 0.00016613118653236518,
      "loss": 0.2861,
      "step": 270
    },
    {
      "epoch": 0.002647697803120028,
      "grad_norm": 0.5697981119155884,
      "learning_rate": 0.000163742398974869,
      "loss": 0.2552,
      "step": 280
    },
    {
      "epoch": 0.0027422584389457435,
      "grad_norm": 0.8980145454406738,
      "learning_rate": 0.00016129070536529766,
      "loss": 0.2826,
      "step": 290
    },
    {
      "epoch": 0.002836819074771459,
      "grad_norm": 0.864953339099884,
      "learning_rate": 0.00015877852522924732,
      "loss": 0.2795,
      "step": 300
    },
    {
      "epoch": 0.002931379710597174,
      "grad_norm": 0.8755021095275879,
      "learning_rate": 0.00015620833778521307,
      "loss": 0.3035,
      "step": 310
    },
    {
      "epoch": 0.0030259403464228895,
      "grad_norm": 0.6392521262168884,
      "learning_rate": 0.00015358267949789966,
      "loss": 0.2943,
      "step": 320
    },
    {
      "epoch": 0.0031205009822486045,
      "grad_norm": 0.7333807349205017,
      "learning_rate": 0.00015090414157503714,
      "loss": 0.2729,
      "step": 330
    },
    {
      "epoch": 0.00321506161807432,
      "grad_norm": 0.7244869470596313,
      "learning_rate": 0.00014817536741017152,
      "loss": 0.2986,
      "step": 340
    },
    {
      "epoch": 0.003309622253900035,
      "grad_norm": 0.6292321681976318,
      "learning_rate": 0.00014539904997395468,
      "loss": 0.2989,
      "step": 350
    },
    {
      "epoch": 0.0034041828897257505,
      "grad_norm": 0.7638192772865295,
      "learning_rate": 0.00014257792915650728,
      "loss": 0.2668,
      "step": 360
    },
    {
      "epoch": 0.003498743525551466,
      "grad_norm": 0.6577920317649841,
      "learning_rate": 0.00013971478906347806,
      "loss": 0.2569,
      "step": 370
    },
    {
      "epoch": 0.003593304161377181,
      "grad_norm": 0.5583338737487793,
      "learning_rate": 0.00013681245526846783,
      "loss": 0.2571,
      "step": 380
    },
    {
      "epoch": 0.0036878647972028965,
      "grad_norm": 0.627045750617981,
      "learning_rate": 0.00013387379202452917,
      "loss": 0.2491,
      "step": 390
    },
    {
      "epoch": 0.0037824254330286115,
      "grad_norm": 0.8836803436279297,
      "learning_rate": 0.00013090169943749476,
      "loss": 0.2679,
      "step": 400
    },
    {
      "epoch": 0.003876986068854327,
      "grad_norm": 1.090550184249878,
      "learning_rate": 0.00012789911060392294,
      "loss": 0.2871,
      "step": 410
    },
    {
      "epoch": 0.003971546704680042,
      "grad_norm": 0.9364948868751526,
      "learning_rate": 0.0001248689887164855,
      "loss": 0.2797,
      "step": 420
    },
    {
      "epoch": 0.0040661073405057575,
      "grad_norm": 0.8688815236091614,
      "learning_rate": 0.00012181432413965428,
      "loss": 0.2553,
      "step": 430
    },
    {
      "epoch": 0.004160667976331473,
      "grad_norm": 0.8005673289299011,
      "learning_rate": 0.00011873813145857249,
      "loss": 0.2685,
      "step": 440
    },
    {
      "epoch": 0.0042552286121571884,
      "grad_norm": 0.6640504598617554,
      "learning_rate": 0.0001156434465040231,
      "loss": 0.2612,
      "step": 450
    },
    {
      "epoch": 0.004349789247982903,
      "grad_norm": 0.7306011319160461,
      "learning_rate": 0.00011253332335643043,
      "loss": 0.2704,
      "step": 460
    },
    {
      "epoch": 0.0044443498838086185,
      "grad_norm": 0.7204407453536987,
      "learning_rate": 0.00010941083133185146,
      "loss": 0.2544,
      "step": 470
    },
    {
      "epoch": 0.004538910519634334,
      "grad_norm": 0.6536638736724854,
      "learning_rate": 0.00010627905195293135,
      "loss": 0.252,
      "step": 480
    },
    {
      "epoch": 0.0046334711554600495,
      "grad_norm": 0.9100165367126465,
      "learning_rate": 0.00010314107590781284,
      "loss": 0.2684,
      "step": 490
    },
    {
      "epoch": 0.004728031791285765,
      "grad_norm": 0.7633541226387024,
      "learning_rate": 0.0001,
      "loss": 0.2764,
      "step": 500
    }
  ],
  "logging_steps": 10,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3724453871616000.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
